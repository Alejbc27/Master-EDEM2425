# âš™ï¸ MODULE 2: Data Processing & Engineering

This module focused on the development of modern, scalable data pipelines â€” both batch and streaming â€” to transform raw data into structured, reliable, and usable assets.

Throughout the process, I worked with key data engineering tools and patterns to manage ingestion, transformation, validation, and delivery across various systems.

---

## âœ… Key Learnings

ğŸ”„ **Data Ingestion with Apache NiFi**  
Designed flow-based pipelines to automate data movement between systems and apply real-time processing logic.

ğŸ“¡ **Change Data Capture (CDC)**  
Implemented patterns to capture and stream changes from source databases, enabling near real-time synchronization.

ğŸƒ **NoSQL with MongoDB**  
Explored document-oriented databases to store and query semi-structured data efficiently.

ğŸ“¬ **Streaming with Apache Kafka**  
Developed real-time pipelines using Kafka producers and consumers, including topic management and message filtering.

âš¡ **Distributed Processing with PySpark**  
Applied PySpark for scalable data transformations, aggregations, and analytics on large datasets.

ğŸ› ï¸ **Data Modeling with DBT**  
Created modular, version-controlled transformation models directly within the data warehouse.

ğŸ“Š **Visualization with Tableau & Power BI**  
Designed dashboards to communicate insights and support decision-making using modern BI tools.

---

## ğŸ“‚ Folder Overview

ğŸ“¬ **Kafka Streaming Project**  
A real-time data pipeline using Kafka: JSON messages are produced, consumed, filtered, and streamed to new topics. Includes real-time querying via KSQL.

âš¡ **PySpark Data Project**  
End-to-end batch pipeline including data cleaning, joins, and aggregations across multiple datasets. Final output is loaded into a MySQL database.

ğŸ› ï¸ **DBT Transformations**  
SQL-based models for transforming raw data into structured outputs inside the data warehouse, fully integrated with version control.

ğŸ“Š **BI Dashboards**  
Dashboard examples built in Tableau and Power BI to visualize processed data and extract key business insights.

---

ğŸ¯ *Goal of the Module:*  
To build reliable, automated data pipelines that deliver clean, trusted data ready for analytics, reporting, or production use â€” at scale and in real time.
